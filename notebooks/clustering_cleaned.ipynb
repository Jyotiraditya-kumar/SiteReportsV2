{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from pyforest import * \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.cluster.hierarchy import dendrogram, linkage\n",
    "from sklearn import metrics\n",
    "from sklearn.cluster import DBSCAN, KMeans\n",
    "from sklearn import metrics\n",
    "import pandas as pd\n",
    "import shapely\n",
    "import geopandas as gpd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "object of type 'Point' has no len()",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[18], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mshapely\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mshapely\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mPoint\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mTypeError\u001b[0m: object of type 'Point' has no len()"
     ]
    }
   ],
   "source": [
    "import shapely\n",
    "len(shapely.Point())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\n",
    "    \"/home/jyotiraditya/PycharmProjects/SiteReports/data/common_data/chennai/raw/location_poi_data.csv\"\n",
    ")[\n",
    "    [\n",
    "        \"id\",\n",
    "        \"name\",\n",
    "        \"lat\",\n",
    "        \"lng\",\n",
    "        \"top_category\",\n",
    "        \"category\",\n",
    "        \"brand_name\",\n",
    "        \"brand_id\",\n",
    "        \"number_of_votes\",\n",
    "    ]\n",
    "]\n",
    "# mask = (\n",
    "#     ((data[\"category\"] == \"restaurant\") & (data[\"number_of_votes\"] > 0) & (data[\"brand_id\"] != \"N_A\"))|\n",
    "#     ((data[\"category\"] == \"clothing_store\") & (data[\"number_of_votes\"] > 0) & (data[\"brand_id\"] != \"N_A\"))|\n",
    "#     ((data[\"category\"] == \"coffee_shop\") & (data[\"number_of_votes\"] > 10) & (data[\"brand_id\"] != \"NAA\"))|\n",
    "#     ((data[\"category\"] == \"shoe_store\") & (data[\"number_of_votes\"] > 0) & (data[\"brand_id\"] != \"N_A\"))|\n",
    "#     ((data[\"category\"] == \"jewelry_store\") & (data[\"number_of_votes\"] > 10) & (data[\"brand_id\"] != \"NAA\"))|\n",
    "#     ((data[\"category\"] == \"gym_fitness\") & (data[\"number_of_votes\"] > 10) & (data[\"brand_id\"] != \"NAA\"))|\n",
    "#     ((data[\"category\"] == \"bar_pub\") & (data[\"number_of_votes\"] > 10) & (data[\"brand_id\"] != \"NAA\"))\n",
    "    \n",
    "# )\n",
    "mask = (\n",
    "    data[\"category\"].isin(\n",
    "        [\n",
    "            \"restaurant\",\n",
    "            \"clothing_store\",\n",
    "            \"coffee_shop\",\n",
    "            \"shoe_store\",\n",
    "            \"jewelry_store\",\n",
    "            \"gym_fitness\",\n",
    "            \"bar_pub\",\n",
    "        ]\n",
    "    )\n",
    ") & ((data[\"number_of_votes\"] > 100) | (data[\"brand_id\"] != \"N_A\"))\n",
    "data = data[mask]\n",
    "# data = data[data[\"city_name\"] == \"ahmedabad\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'geopandas' has no attribute 'point_from_xy'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[92], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m data_gdf\u001b[38;5;241m=\u001b[39mgpd\u001b[38;5;241m.\u001b[39mGeoDataFrame(data,geometry\u001b[38;5;241m=\u001b[39m\u001b[43mgpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpoint_from_xy\u001b[49m(data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlng\u001b[39m\u001b[38;5;124m'\u001b[39m],data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlat\u001b[39m\u001b[38;5;124m'\u001b[39m]))\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'geopandas' has no attribute 'point_from_xy'"
     ]
    }
   ],
   "source": [
    "data_gdf=gpd.GeoDataFrame(data,geometry=gpd.point_from_xy(data['lng'],data['lat']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cluster_by_dbscan(df):\n",
    "    data_array = np.radians(df[[\"lat\", 'lng']].to_numpy())\n",
    "    db = DBSCAN(eps=0.150/6371., min_samples=20, algorithm='ball_tree', metric='haversine').fit(data_array)\n",
    "    df['label'] = db.labels_\n",
    "    return df\n",
    "\n",
    "def cluster_by_kmeans(df,num_clusters=60):\n",
    "    data_array = np.radians(df[[\"lat\", 'lng']].to_numpy())\n",
    "    km=KMeans(n_clusters=num_clusters).fit(data_array)\n",
    "    df['label'] = km.labels_\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from keplergl import KeplerGl\n",
    "# map_2 = KeplerGl(height=1024, data={\"data_1\": df},  )\n",
    "# map_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11455, 9)\n",
      "(2969, 10)\n"
     ]
    }
   ],
   "source": [
    "df=data.copy()\n",
    "print(df.shape)\n",
    "df=cluster_by_dbscan(df)\n",
    "df=df[df['label']!=-1]\n",
    "print(df.shape)\n",
    "# df=df.drop(columns=['label'])\n",
    "# df=cluster_by_kmeans(df,50)\n",
    "\n",
    "df.rename(columns={\"label\": \"micro_market_clusters\"}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"mysuru micro market clusters.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "df['geom_point'] = df.apply(lambda x: shapely.Point(x['lng'], x['lat']), axis=1)\n",
    "df_ = df\n",
    "\n",
    "clusters = df_.groupby(\"micro_market_clusters\").agg(geom_point=(\"geom_point\", list)).reset_index()\n",
    "clusters.drop(clusters[clusters[\"micro_market_clusters\"] ==-1].index, inplace=True)\n",
    "# clusters.drop(clusters[clusters[\"micro_market_clusters\"] < 5].index, inplace=True)\n",
    "\n",
    "clusters[\"multipolygon\"] = clusters[\"geom_point\"].apply(lambda x: shapely.MultiPoint(x).convex_hull)\n",
    "clusters['multipolygon']= clusters['multipolygon'].apply(lambda x: x.simplify(0.001 ).wkt)\n",
    "\n",
    "clusters[\"num_points\"] = clusters[\"geom_point\"].apply(lambda x: len(x))\n",
    "clusters.drop(clusters[clusters[\"num_points\"] < 10].index, inplace=True)\n",
    "\n",
    "clusters.drop(columns=[\"geom_point\"], inplace=True)\n",
    "\n",
    "clusters_gdf = gpd.GeoDataFrame(clusters, geometry=gpd.GeoSeries.from_wkt(clusters[\"multipolygon\"]), crs=\"EPSG:4326\")\n",
    "clusters_gdf.to_crs(6933, inplace=True)\n",
    "clusters_gdf[\"area\"] = clusters_gdf[\"geometry\"].area/1e6\n",
    "clusters_gdf.to_crs(4326, inplace=True)\n",
    "\n",
    "clusters_gdf[\"point_density\"]  = clusters_gdf[\"num_points\"]/clusters_gdf[\"area\"]\n",
    "clusters_gdf['centroid'] = clusters_gdf.centroid\n",
    "clusters_gdf_ = clusters_gdf.drop(columns=[\"geometry\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "clusters_gdf_.to_csv(\"../data/common_data/chennai/high_streets.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_large_polygon_by_density(polygon, points, base_polygon_area=0):\n",
    "    if type(polygon) == str:\n",
    "        polygon = shapely.from_wkt(polygon)\n",
    "    try:\n",
    "        from sklearn.cluster import KMeans\n",
    "        polygon_area = polygon.area\n",
    "        if polygon_area < base_polygon_area:\n",
    "            return [polygon]\n",
    "        else:\n",
    "            num_splits = min( int(polygon_area / base_polygon_area), 4 )\n",
    "            kmeans = KMeans(n_clusters=num_splits)\n",
    "            kmeans.fit(points)\n",
    "\n",
    "            cluster_labels = kmeans.labels_\n",
    "            cluster_centers = kmeans.cluster_centers_\n",
    "            points_by_poly = []\n",
    "            for i in np.unique(cluster_labels):\n",
    "                points_by_poly.append(points[cluster_labels == i])\n",
    "            \n",
    "            polygons = []\n",
    "            for points in points_by_poly:\n",
    "                polygon = shapely.MultiPoint([shapely.Point(i[0], i[1]) for i in points]).convex_hull.simplify(0.001)\n",
    "                polygons.append(polygon)\n",
    "            \n",
    "            return polygons\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        return [polygon]\n",
    "\n",
    "def geom_area_in_sqkm(geom):\n",
    "    import contextlib\n",
    "    import io\n",
    "    import sys\n",
    "    null_io = io.StringIO()\n",
    "    with contextlib.redirect_stdout(null_io):\n",
    "        if type(geom) == str:\n",
    "            geom = shapely.from_wkt(geom)\n",
    "        from pyproj import Geod\n",
    "        geod = Geod(ellps=\"WGS84\")\n",
    "        area = geod.geometry_area_perimeter(geom)[0] / 10**6\n",
    "    return -area if area < 0 else area\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "clusters_gdf_['sub_polygons'] = clusters_gdf_.apply( lambda x: split_large_polygon_by_density(x['multipolygon'],df[df['micro_market_clusters'] == x['micro_market_clusters']][['lng', 'lat']].to_numpy(),0.000032), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_polygons_after_split = clusters_gdf_['sub_polygons'].explode()\n",
    "clusters_gdf_['len_sub_polygons'] = clusters_gdf_['sub_polygons'].apply(lambda x: len(x))\n",
    "\n",
    "clusters_gdf_ = pd.DataFrame(cluster_polygons_after_split).reset_index(drop=True)\n",
    "clusters_gdf_ = clusters_gdf_.reset_index().rename(columns={\"index\": \"micro_market_clusters_id\", \"sub_polygons\": \"polygon\"})\n",
    "clusters_gdf_['centroid'] = clusters_gdf_['polygon'].apply(lambda x: x.centroid)\n",
    "clusters_gdf_['lat'] = clusters_gdf_['centroid'].apply(lambda x: x.y)\n",
    "clusters_gdf_['lng'] = clusters_gdf_['centroid'].apply(lambda x: x.x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clusters_gdf_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "clusters_gdf_.to_csv(\"../data/common_data/chennai/high_streets.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "def buffer_a_polygon_in_meters(polygon, meters):\n",
    "    import pyproj\n",
    "    from shapely.ops import transform\n",
    "    \n",
    "    wgs84 = pyproj.CRS('EPSG:4326')\n",
    "    utm = pyproj.CRS('EPSG:32618')\n",
    "    project_1 = pyproj.Transformer.from_crs(wgs84, utm, always_xy=True).transform\n",
    "    project_2 = pyproj.Transformer.from_crs(utm, wgs84, always_xy=True).transform\n",
    "\n",
    "    if type(polygon) == str:\n",
    "        polygon = shapely.from_wkt(polygon)\n",
    "    if meters > 0:\n",
    "        polygon = transform(project_1, polygon)\n",
    "        polygon = polygon.buffer(meters)\n",
    "        polygon = transform(project_2, polygon)\n",
    "    return polygon\n",
    "\n",
    "def buffer_polygons(polygon,min,max, buffer_area_cutt_off):\n",
    "    if type(polygon) == str:\n",
    "        polygon = shapely.from_wkt(polygon)\n",
    "    area = geom_area_in_sqkm(polygon)*1e6\n",
    "    if area < buffer_area_cutt_off:\n",
    "        amount_to_buffer = np.sqrt( (buffer_area_cutt_off - area) / (2*3.14)  )\n",
    "        amount_to_buffer = np.clip(amount_to_buffer, min, max)\n",
    "        polygon = buffer_a_polygon_in_meters(polygon, amount_to_buffer)\n",
    "    return polygon\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "clusters_gdf_['polygon_updated'] = clusters_gdf_['polygon'].apply(lambda x: buffer_polygons(x, 0, 300,  0.26 * 1e6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "clusters_gdf_.to_csv(\"../data/common_data/chennai/high_streets.csv\",index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
